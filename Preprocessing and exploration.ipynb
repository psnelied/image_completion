{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0057fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data \n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365bae",
   "metadata": {},
   "source": [
    "# CELEBA DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cecf7e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data_faces: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
    "  zip_ref.extractall(\"data_faces/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c835b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ \n",
    "                                transforms.Resize(size=(160, 160)),\n",
    "                                transforms.ToTensor(),\n",
    "                               ])\n",
    "     \n",
    "sep = 190000 #trainset size\n",
    "\n",
    "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
    "trainset, testset = torch.utils.data.random_split(celeba_data, lengths=(sep,len(celeba_data)-sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989392d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# subset to work on less values\n",
    "\n",
    "trainset = Subset(trainset, np.arange(10000))\n",
    "testset = Subset(testset, np.arange(1000))\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12eb216",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966869cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img): \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images,_ = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:16]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
