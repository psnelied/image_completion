{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363bdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data \n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from model import Completion_Network,Context_Discriminators\n",
    "from train_model import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_network = Completion_Network()\n",
    "context_discriminators = Context_Discriminators()\n",
    "\n",
    "mseloss = nn.MSELoss()\n",
    "bceloss = nn.BCELoss()\n",
    "\n",
    "completion_losses = []\n",
    "discriminator_losses = []\n",
    "joint_losses = []\n",
    "test_loss_C = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ \n",
    "                                transforms.Resize(size=(160, 160)),\n",
    "                                transforms.ToTensor(),\n",
    "                               ])\n",
    "     \n",
    "sep = 190000 #trainset size\n",
    "\n",
    "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
    "trainset, testset = torch.utils.data.random_split(celeba_data, lengths=(sep,len(celeba_data)-sep))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# subset to work on less values\n",
    "\n",
    "trainset = Subset(trainset, np.arange(10000))\n",
    "testset = Subset(testset, np.arange(1000))\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_losses, discrimination_losses, joint_losses, test_loss_C = train(completion_network=completion_network, \n",
    "                                                                    context_discriminators=context_discriminators, \n",
    "                                                                    train_loader=train_loader, test_loader=test_loader, \n",
    "                                                                    n_epoch = 3, tc = 1, td = 1,\n",
    "                                                                    test_period = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a09a2",
   "metadata": {},
   "source": [
    "# Save the completion model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "model_save_name = 'completion_network.pt'\n",
    "path = \"{}\".format(model_save_name)\n",
    "torch.save(completion_network.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "model_save_name = 'completion_network.pt'\n",
    "path = \"{}\".format(model_save_name)\n",
    "completion_network_load = Completion_Network()\n",
    "completion_network_load.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79e503",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(joint_losses))\n",
    "plt.plot(x, joint_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74275ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(discrimination_losses))\n",
    "plt.plot(x, discrimination_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08323cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(completion_losses))\n",
    "plt.plot(x, completion_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(test_loss_C))\n",
    "plt.plot(x, test_loss_C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08d1c0",
   "metadata": {},
   "source": [
    "# Postprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(masked_images, output_completion, mask, radius = 3):\n",
    "    \n",
    "    batch_size = masked_images.shape[0]\n",
    "    result = []\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        #fast marching method\n",
    "        \n",
    "        src = masked_images[i].numpy().transpose(1,2,0)\n",
    "        src = src*255.\n",
    "        src = src.astype(np.uint8)\n",
    "               \n",
    "        mask_i = mask[i].numpy().transpose(1,2,0)\n",
    "        mask_i = mask_i*255.\n",
    "        mask_i = mask_i.astype(np.uint8)        \n",
    "    \n",
    "        dst = cv2.inpaint(src, mask_i, radius, cv2.INPAINT_TELEA) \n",
    "\n",
    "        #Poisson blending\n",
    "\n",
    "        src = output_completion[i].numpy().transpose(1,2,0)\n",
    "        src = src*255.\n",
    "        src = src.astype(np.uint8) \n",
    "\n",
    "        center = mask_center(mask_i)\n",
    "        mask_i = np.repeat(mask_i, repeats=3, axis = 2)\n",
    "\n",
    "        blend = cv2.seamlessClone(src, dst, mask_i, center, cv2.NORMAL_CLONE)\n",
    "        blend = transforms.ToTensor()(blend).unsqueeze(0)\n",
    "        result.append(blend)\n",
    "\n",
    "    result = torch.cat(result)\n",
    "    return result\n",
    "\n",
    "def mask_center(mask):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if mask[i, j, 0] == 255:\n",
    "                x.append(j)\n",
    "                y.append(i)        \n",
    "    x_start = min(x)\n",
    "    x_end = max(x)\n",
    "    y_start = min(y)\n",
    "    y_end = max(y)\n",
    "    center = ((x_start + x_end) // 2, (y_start + y_end) // 2)\n",
    "    return center  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i,(test_images, _) in enumerate(test_loader):\n",
    "         if i == 1 :\n",
    "            mask, _ = generate_mask(input_shape=(test_images.shape[0], 1, test_images.shape[2], test_images.shape[3]), patch=(48,48), size=([24,48], [24,48]), n_holes=2)\n",
    "            masked_images = test_images - test_images * mask + mpv * mask\n",
    "            masked_images = masked_images.cuda()\n",
    "            mask = mask.cuda()\n",
    "            input = torch.cat((masked_images, mask), dim=1)\n",
    "            output = completion_network(input) \n",
    "            masked_images = masked_images.cpu()\n",
    "            output = output.cpu()\n",
    "            mask = mask.cpu()\n",
    "            output_final = postprocessing(masked_images, output, mask)\n",
    "            inputs = torch.cat((masked_images[0].unsqueeze(0), output_final[0].unsqueeze(0), test_images[0].unsqueeze(0)))\n",
    "            imshow_2(torchvision.utils.make_grid(inputs))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
