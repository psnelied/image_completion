{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d146ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data \n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e147d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(completion_network, context_discriminators, train_loader, test_loader, \n",
    "          n_epoch = 20, tc = 5, td = 2, alpha=0.0004,\n",
    "          test_period = 5):\n",
    "\n",
    "    try :\n",
    "        print(\"using cuda\")\n",
    "        completion_network.cuda()\n",
    "        context_discriminators.cuda()\n",
    "        mpv.cuda()\n",
    "    except :\n",
    "        print(\"cuda not available\")\n",
    "\n",
    "    optimizer_C = torch.optim.Adadelta(completion_network.parameters())\n",
    "    optimizer_D = torch.optim.Adadelta(context_discriminators.parameters())\n",
    "\n",
    "    print_step1 = True;\n",
    "    print_step2 = True;\n",
    "    print_step3 = True;\n",
    "    \n",
    "    completion_network.train()\n",
    "    context_discriminators.train()\n",
    "\n",
    "    for t in range(n_epoch): ###################  Step 1 ###################\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if t < tc :\n",
    "\n",
    "            if print_step1:  \n",
    "                print(\"====== Training completion network ======\")\n",
    "                print_step1 = False\n",
    "            \n",
    "            running_loss_C = 0\n",
    "\n",
    "            for i,(images, _) in enumerate(train_loader):  #sample mini batches from training data\n",
    "\n",
    "                images = images.type(torch.cuda.FloatTensor)\n",
    "                mask_c, region_c = generate_mask(input_shape=(images.shape[0], 1, images.shape[2], images.shape[3]))\n",
    "                mask_c = mask_c.cuda()\n",
    "                \n",
    "                optimizer_C.zero_grad()\n",
    "\n",
    "                masked_images = images - images * mask_c + mpv * mask_c\n",
    "                input_completion = torch.cat((masked_images, mask_c), dim=1)\n",
    "                output_completion = completion_network(input_completion)\n",
    "\n",
    "                #if (i%100==0):\n",
    "                    #masked_img = masked_images.cpu()\n",
    "                    #output = output_completion.cpu()\n",
    "                    #inputs = torch.cat((masked_img[0].unsqueeze(0), output[0].unsqueeze(0)))\n",
    "                    #imshow_2(torchvision.utils.make_grid(inputs))\n",
    "\n",
    "\n",
    "                #loss_C = mseloss(output_completion * mask_c, images * mask_c)\n",
    "                loss_C = mseloss(output_completion, images)\n",
    "                running_loss_C += loss_C.item()\n",
    "                                \n",
    "                loss_C.backward()\n",
    "                optimizer_C.step()\n",
    "\n",
    "            running_loss_C/=len(train_loader)\n",
    "            completion_losses.append(running_loss_C)   \n",
    "            end_time = time.time() - start_time\n",
    "            minute = int(end_time/60)\n",
    "            sec = int(end_time%60)\n",
    "            print(\"Epoch {}: loss_C = {:.5f} - {} min {} s \".format(t+1, running_loss_C, minute, sec))\n",
    "\n",
    "            if (t+1) % test_period == 0:\n",
    "                # torch.save(completion_network.state_dict(), \"completion_network_tc.pt\")  # on Azure\n",
    "                running_loss = 0\n",
    "                completion_network.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i,(test_images, _) in enumerate(test_loader):\n",
    "                        test_images = test_images.type(torch.cuda.FloatTensor)\n",
    "                        mask, _ = generate_mask(input_shape=(test_images.shape[0], 1, test_images.shape[2], test_images.shape[3]))\n",
    "                        mask = mask.cuda()\n",
    "                        masked_images = test_images - test_images * mask + mpv * mask\n",
    "                        input = torch.cat((masked_images, mask), dim=1)\n",
    "                        output = completion_network(input) \n",
    "                        #loss = mseloss(output * mask, test_images * mask)\n",
    "                        loss = mseloss(output, test_images)\n",
    "                        running_loss += loss.item()       \n",
    "                running_loss/=len(test_loader)\n",
    "                test_loss_C.append(running_loss)\n",
    "                completion_network.train()   \n",
    "                print(\"         test_loss_C = {:.5f}\".format(running_loss))\n",
    "\n",
    "          \n",
    "        elif t < tc + td:  ###################  Step 2 ###################\n",
    "\n",
    "            running_loss_D = 0\n",
    "\n",
    "            if print_step2:  \n",
    "                    print(\"====== Training context discriminators ======\")\n",
    "                    print_step2 = False\n",
    "\n",
    "            for i,(images, _) in enumerate(train_loader):  #sample mini batches from training data\n",
    "\n",
    "                images = images.type(torch.cuda.FloatTensor)\n",
    "                mask_c, region_c = generate_mask(input_shape=(images.shape[0], 1, images.shape[2], images.shape[3]))\n",
    "                mask_c = mask_c.cuda()\n",
    "\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                # fake images\n",
    "                masked_images = images - images * mask_c + mpv * mask_c\n",
    "                input_completion = torch.cat((masked_images, mask_c), dim=1)\n",
    "                output_completion = completion_network(input_completion) \n",
    "                input_local_fake = crop(output_completion, region_c)\n",
    "                input_global_fake = output_completion                 \n",
    "                output_fake = context_discriminators((input_local_fake.cuda(), input_global_fake.cuda()))  #probability to be real - we want = 0 \n",
    "                zeros = torch.zeros((len(images), 1)).cuda()\n",
    "                loss_fake = bceloss(output_fake, zeros)\n",
    "\n",
    "                # real images\n",
    "                region = random_patch()\n",
    "                input_local_real = crop(images, region)  \n",
    "                input_global_real = images\n",
    "                output_real = context_discriminators((input_local_real, input_global_real)) #probability to be real - we want = 1\n",
    "                ones = torch.ones((len(images), 1)).cuda()\n",
    "                loss_real = bceloss(output_real, ones)\n",
    "\n",
    "                loss_D = 0.5 * (loss_fake + loss_real)\n",
    "   \n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "                running_loss_D += loss_D.item()                       \n",
    "            \n",
    "            #if t == tc + td - 1:\n",
    "                #torch.save(context_discriminators.state_dict(), \"context_discriminators_td.pt\")\n",
    "                \n",
    "            running_loss_D/=len(train_loader)   \n",
    "            discriminator_losses.append(running_loss_D)   \n",
    "            end_time = time.time() - start_time\n",
    "            minute = int(end_time/60)\n",
    "            sec = int(end_time%60)\n",
    "            print(\"Epoch {}: loss_D = {:.5f} - {} min {} s\".format(t+1, running_loss_D, minute, sec))\n",
    "            print(\"last batch : loss fake = {:.5f}\".format(loss_fake.item()), \"loss real = {:.5f}\".format(loss_real.item()))\n",
    "      \n",
    "                \n",
    "        else : ###################  Step 3 ####################\n",
    "\n",
    "            if print_step3:  \n",
    "                print(\"====== Training both ======\")\n",
    "                print_step3 = False\n",
    "\n",
    "            running_loss_C = 0\n",
    "            running_loss_D = 0\n",
    "            running_joint_loss = 0\n",
    "\n",
    "            for i,(images, _) in enumerate(train_loader):  #sample mini batches from training data\n",
    "\n",
    "                images = images.type(torch.cuda.FloatTensor)\n",
    "                mask_c, region_c = generate_mask(input_shape=(images.shape[0], 1, images.shape[2], images.shape[3]))\n",
    "                mask_c = mask_c.cuda()\n",
    "\n",
    "                optimizer_C.zero_grad()\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                masked_images = images - images * mask_c + mpv * mask_c\n",
    "                input_completion = torch.cat((masked_images, mask_c), dim=1)\n",
    "                output_completion = completion_network(input_completion) \n",
    "\n",
    "                #loss_C = mseloss(output_completion * mask_c, images * mask_c)\n",
    "                loss_C = mseloss(output_completion, images)\n",
    "\n",
    "                # fake images\n",
    "                input_global_fake = output_completion.detach() \n",
    "                input_local_fake = crop(input_global_fake, region_c)\n",
    "                output_fake = context_discriminators((input_local_fake, input_global_fake))  #probability to be real - we want = 0 \n",
    "                zeros = torch.zeros((len(images), 1)).cuda()\n",
    "                loss_fake = bceloss(output_fake, zeros)\n",
    "\n",
    "                # real images\n",
    "                region = random_patch()\n",
    "                input_local_real = crop(images, region)    \n",
    "                input_global_real = images\n",
    "                output_real = context_discriminators((input_local_real, input_global_real)) #probability to be real - we want = 1\n",
    "                ones = torch.ones((len(images), 1)).cuda()\n",
    "                loss_real = bceloss(output_real, ones)\n",
    "\n",
    "                loss_D = 0.5 * alpha * (loss_fake + loss_real)\n",
    "                #if loss_D.item()>0.0002 : #threshold\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                input_local_fake = crop(output_completion, region_c)\n",
    "                input_global_fake = output_completion\n",
    "                output_fake = context_discriminators((input_local_fake, input_global_fake))\n",
    "                loss_fake_2 = bceloss(output_fake, ones)  #the completion network wants to minimize this loss\n",
    "\n",
    "                joint_loss = 0.5 * (loss_C + alpha * loss_fake_2)\n",
    "                joint_loss.backward()\n",
    "                optimizer_C.step()     \n",
    "\n",
    "                running_loss_C += loss_C.item()\n",
    "                running_loss_D += loss_D.item()   \n",
    "                running_joint_loss += joint_loss.item()  \n",
    "                \n",
    "            running_loss_C/=len(train_loader)\n",
    "            running_loss_D/=len(train_loader) \n",
    "            running_joint_loss/=len(train_loader)\n",
    "            completion_losses.append(running_loss_C)\n",
    "            discriminator_losses.append(running_loss_D)   \n",
    "            joint_losses.append(running_joint_loss)\n",
    "            \n",
    "            end_time = time.time() - start_time\n",
    "            minute = int(end_time/60)\n",
    "            sec = int(end_time%60)\n",
    "            print(\"Epoch {}: loss_C = {:.5f}, loss_D = {:.5f}, joint_loss = {:.5f} - {} min {} s\".format(t+1, running_loss_C, running_loss_D, \n",
    "                                                                                                         running_joint_loss, minute, sec))\n",
    "            print(\"last batch : loss fake D = {:.5f}\".format(loss_fake.item()), \"loss real D = {:.5f}\".format(loss_real.item()),\n",
    "                 \"loss_fake C = {:.5f}\".format(loss_fake_2.item()))\n",
    " \n",
    "            if (t+1) % test_period == 0:\n",
    "                #torch.save(completion_network.state_dict(), \"completion_network.pt\")\n",
    "                #torch.save(context_discriminators.state_dict(), \"context_discriminators.pt\")\n",
    "                \n",
    "                running_loss = 0\n",
    "                completion_network.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i,(test_images, _) in enumerate(test_loader):\n",
    "                        test_images = test_images.type(torch.cuda.FloatTensor)\n",
    "                        mask, _ = generate_mask(input_shape=(test_images.shape[0], 1, test_images.shape[2], test_images.shape[3]))\n",
    "                        mask = mask.cuda()\n",
    "                        masked_images = test_images - test_images * mask + mpv * mask\n",
    "                        input = torch.cat((masked_images, mask), dim=1)\n",
    "                        output = completion_network(input) \n",
    "                        #loss = mseloss(output * mask, test_images * mask)\n",
    "                        loss = mseloss(output, test_images)\n",
    "                        running_loss += loss.item()\n",
    "             \n",
    "                running_loss/=len(test_loader)\n",
    "                test_loss_C.append(running_loss)\n",
    "                completion_network.train()\n",
    "                print(\"         test_loss_C = {:.5f}\".format(running_loss))\n",
    "                                \n",
    "    print(\"Finished Training\")\n",
    "    #torch.save(completion_network.state_dict(), \"completion_network.pt\")\n",
    "    #torch.save(context_discriminators.state_dict(), \"context_discriminators.pt\")\n",
    "    return completion_losses, discriminator_losses, joint_losses, test_loss_C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
